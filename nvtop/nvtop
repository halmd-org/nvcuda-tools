#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# reformat output of the nvidia-smi tool
#
# Copyright © 2011-2018  Felix Höfling
#
# This tool is free software and released under the terms of
# the GNU General Public License Version 3, please refer to
# <http://www.gnu.org/licenses/> for details.

from subprocess import Popen, PIPE
from xml.etree import ElementTree
from re import search, sub

# grab output of nvidia-smi tool
try:
    nvsmi = Popen(['nvidia-smi', '-a', '-x'], stdout=PIPE).communicate()[0]
except:
    raise SystemExit("Error while reading from nvidia-smi")

# parse XML
xmlt = ElementTree.XML(nvsmi)

# get GPU names and their lengths first
gpu_name = []
max_len = 0
for id,gpu in enumerate(xmlt.iter(tag="gpu")):
    s = gpu.findtext("prod_name") or gpu.findtext("product_name") or "n/a"
    s = sub(' Processor', '', s) # simplify name
    gpu_name += [s,]
    max_len = max(max_len, len(s))

# add trailing space and round up to multiple of 4
max_len += 1
max_len = int((max_len + 3) / 4) * 4

# print header
print('''\
ID  Name{0:s}Utilization     Temp    Fan     Processes
        {0:s}GPU   Memory                    ID      Memory    Name\
'''.format(" " * (max_len - len("Name"))))

# retrieve GPU information from XML groups
for id,gpu in enumerate(xmlt.iter(tag="gpu")):
    info = {}
    info["name"] = gpu_name[id].ljust(max_len)
    info["id"] = '{0:d}'.format(id)
    info["temp"] = gpu.findtext("temp") or gpu.findtext("temperature/gpu_temp") or ""
    info["fan"] = gpu.findtext("fan_speed") or ""
    info["gpu_util"] = gpu.findtext("utilization/gpu_util") or ""
    info["mem_util"] = gpu.findtext("utilization/memory_util") or ""

    info["proc"] = ""
    compute = gpu.find("processes")
    if compute is None:
        compute = gpu.find("compute_processes")
    if compute is not None:
        first_line = True
        for proc in compute.iter(tag="process_info"):
            if proc.findtext("type") == 'G':
                continue
            pid = proc.findtext("pid")
            mem = proc.findtext("used_memory")
            name = proc.findtext("process_name")
            if not first_line:
                info["proc"] += '\n{0:49}'.format("")
            info["proc"] += '{0:8s}{1:>8s}  {2:16s}'.format(pid, mem, name)
            first_line = False

    # Tesla GPUs of type C1060 or T10 (= S1070) are only partially supported by
    # NVLM (since Nvidia driver version ≥ 304). In particular, the GPU and
    # memory utilizations are "N/A" and the compute processes are not listed.
    # In this case, display at least the total memory used.
    if search('Tesla (T10|C10)', info["name"]) and not len(info["proc"]):
        mem = gpu.findtext("memory_usage/used") or ""
        if int(mem[:-3]) < 10: # suppress displaying the tiny memory usage by the driver
            mem = ""
        info["proc"] = '{0:8s}{1:>8s}'.format("N/A", mem)

    # output data in one line
    print('{id:4s}{name:s}{gpu_util:^5s} {mem_util:^5s}     {temp:8s}{fan:8s}{proc:s}'.format(**info))
